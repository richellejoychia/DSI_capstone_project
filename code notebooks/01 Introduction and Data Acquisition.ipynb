{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60328300-0d21-4793-9219-32f2f5840fcd",
   "metadata": {},
   "source": [
    "# Capstone Project: Travel Recommender System Based on Activity Preferences\n",
    "\n",
    "Done by: Richelle-Joy Chia, [Linkedin](https://www.linkedin.com/in/richelle-joy-chia/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ba5f92-c9bd-4202-b5a8-73ffaa658068",
   "metadata": {},
   "source": [
    "## Outline:\n",
    "\n",
    "- Part 1: Introduction and Data Acquisition\n",
    "- Part 2: Data Cleaning and Exploratory Data Analysis (EDA)\n",
    "- Part 3: Feature Engineering and Recommender System\n",
    "- Part 4: NLP - Sentiment Analysis using Hugging Face\n",
    "- Part 5: Streamlit Deployment \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4363967b-7d46-4a7e-9c37-2ace9be20b71",
   "metadata": {},
   "source": [
    "# Part 1: Introduction and Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e64150-ed34-4d37-99a2-013810bc44b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1.1 Background \n",
    "\n",
    "Travelling is a mixture of journey, transportation, travel-time, events, exploration, and other aspects that are likely to be experienced by a lot of people at some point in their life. A tourist has time and budget limitations; therefore, he would need to select points of interest (POIs) optimally. Since current available information about POIs is overloading, it is difficult for tourists to select the most appropriate ones that can consider their preferences. Therefore, having a travel recommender system that incorporates more specific categories would be a possible solution to overcome the information overload problem.\n",
    "\n",
    "Moreover, unlike other industries (e.g., ecommerce, music, movies), there is no clearly defined catalog of recommendable items in tourism. In fact, what is recognized as a POI for some tourists may not be seen as a tourism target for others. For example, an American tourist may be recommended a visit to a small town in a nearby region of her residency, but this will not be recognized as a compelling target for a Japanese tourist, who will instead consider the whole Italy as a possible destination, maybe in alternative to Mexico. \n",
    "\n",
    "\n",
    "## 1.1.2 Problem Statement\n",
    "\n",
    "Existing systems rarely aim at recommending tangible itineraries for tourists within a specific POI due to the difficulty of acquiring information about the true user behavior, that is, the sequence of experiences that travelers perform. While their online information search activity is easy to be tracked, their true experiences, that is, the POIs they visit, are only known indirectly, in the form of selected reviews, which only specific travlers would usually provide. This is much different from other domains, such as Netflix, where the user's watching behavior is easily tracked and users can experience their \"like\" for a movie by just one click.\n",
    "\n",
    "As a result, recommender-systems in the tourism domain usually suffer from a continuous state of \"coldness\": they do not have enough users preference data to generate effective and personalized recommendations. \n",
    "\n",
    "## 1.1.3 Goal and context of this project\n",
    "The goal of this project is to build a recommender system that would evaluate the overwhelming number of POIs and provide personalized recommendations to users based on their preferences. Another goal would be to deploy this recommender system on Streamlit to kickstart a travel recommender system based on activity preferences as well as to deploy it on Streamlit and google cloud. \n",
    "\n",
    "The content-based recommender system will be built using Cosine Similarity, which is one of the most popular techniques used in recommendation systems. The attributes used were the hand-labelled categories (refer to part 3 Feature Engineering and Recommender System). The intuition behind this sort of recommendation system is that if a user liked a particular type of activity, he/she might like a similar activity. To examine if the recommender system is effetive, I created a survey and did A/B testing as well as User Acceptance Testing (UAT) to see if users are pleased with the recommendations. More details can be found in (part 3 Feature Engineering and Recommender System) as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea107a27-a91e-40f5-bcf2-4ae3d2ae6fb1",
   "metadata": {},
   "source": [
    "## 1.2 Data Acquisition\n",
    "\n",
    "\n",
    "1. Part 1 of the data (e.g., attraction name, url, reviews, country, price, ratings) was retrieved from a group of people who worked on a travel recommender system. [Click here to refer to source.]([https://github.com/sachinnpraburaj/Intelligent-Travel-Recommendation-System/tree/master/outputs](https://github.com/sachinnpraburaj/Intelligent-Travel-Recommendation-System/tree/master/outputs))\n",
    "\n",
    "2. Part 2 of the data (e.g., images, duration, and description) was scraped from TripAdvisor using Selenium. The images and duration were scraped to showcase on Streamlit. As for the description, it was partially used to create the manual labels. This was not included in Streamlit as I wanted to only show information that would capture people's attention instantly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c1a866-6e43-4b12-91bc-6adc7ae78eb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.2.1. Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f23c3996-041e-4527-a5da-f5e833d78d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab3205a-f64a-4015-a56a-9eecb7a0673d",
   "metadata": {},
   "source": [
    "### 1.2.2. Data scraping - [Selenium](https://pypi.org/project/selenium/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30c8acb2-1ee9-48df-b18e-df0f52837bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate webdriver\n",
    "option = webdriver.ChromeOptions()\n",
    "chrome_executable = Service('/Users/richelle-joychia/mambaforge/envs/dsi-sg/bin/chromedriver')\n",
    "driver = webdriver.Chrome(service=chrome_executable)\n",
    "driver.implicitly_wait(15)\n",
    "\n",
    "path_to_file = \"datasets/durationdescriptionimages.csv\"\n",
    "\n",
    "csvFile = open(path_to_file, 'a',  encoding = \"utf-8\")\n",
    "header = [\"attraction_id\", \"attraction\", \"description\", \"duration\", \"images\"]\n",
    "csvWriter = csv.DictWriter(csvFile, fieldnames = header)\n",
    "csvWriter.writeheader()\n",
    "\n",
    "for i in range(len(final_att_data['attraction'])):\n",
    "    \n",
    "# url you want to scrape \n",
    "        cat_url = final_att_data['attraction'][i]\n",
    "        driver.get(cat_url) \n",
    "\n",
    "        # this is where you want to place your csv file. 
    "        path_to_file = \"datasets/durationdescriptionimages.csv\"\n",
    "\n",
    "        try:\n",
    "            WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"span.biGQs._P.pZUbB.egaXP.KxBGd\")))\n",
    "            description = driver.find_elements(By.CSS_SELECTOR, \"div.fIrGe._T.bgMZj\")[0].text   \n",
    "            duration = driver.find_elements(By.CSS_SELECTOR, \"span.biGQs._P.pZUbB.egaXP.KxBGd\")[2].text\n",
    "            images = driver.find_elements(By.CSS_SELECTOR, \"div.Kxegy._R.w._Z.GA\")[0].get_attribute(\"style\")\n",
    "        \n",
    "        except:\n",
    "            \n",
    "            duration = 'NA'\n",
    "            \n",
    "        # create and open csv file\n",
    "        csvFile = open(path_to_file, 'a',  encoding = \"utf-8\")\n",
    "        header = [\"attraction_id\", \"attraction\", \"description\", \"duration\", \"images\"]\n",
    "        csvWriter = csv.DictWriter(csvFile, fieldnames = header)\n",
    "        csvWriter.writerow({\"attraction_id\": final_att_data['attraction_id'][i], \"attraction\":final_att_data['attraction'][i], \"description\": description, \"duration\": duration, \"images\": images})\n",
    "\n",
    "time.sleep(30)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e059a612-b20e-49d3-99a2-e06024a4d260",
   "metadata": {},
   "source": [
    "### 1.2.3 Import and merge datasets retrieved from this [source.](https://github.com/sachinnpraburaj/Intelligent-Travel-Recommendation-System/tree/master/outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42b8b0dd-9e2c-492b-8ab5-6c1b12490d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "attractions1 = pd.read_csv('./raw_datasets/attractions_details_batch1.csv')\n",
    "attractions2 = pd.read_csv('./raw_datasets/attractions_details_batch2.csv')\n",
    "attractions = pd.concat([attractions1,attractions2],ignore_index=True)\n",
    "attractions.drop(labels='location',axis=1,inplace=True)\n",
    "attractions.to_csv('./raw_datasets/attractions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaeccf43-cb5d-4fae-827d-f3fa1e2e6351",
   "metadata": {},
   "outputs": [],
   "source": [
    "attractions_review_batch1_1 = pd.read_csv('./raw_datasets/attactions_reviews_batch1/attractions_reviews_batch1_1.csv')\n",
    "attractions_review_batch1_2 = pd.read_csv('./raw_datasets/attactions_reviews_batch1/attractions_reviews_batch1_2.csv')\n",
    "attractions_review_batch1_3 = pd.read_csv('./raw_datasets/attactions_reviews_batch1/attractions_reviews_batch1_3.csv')\n",
    "attractions_review_batch1_4 = pd.read_csv('./raw_datasets/attactions_reviews_batch1/attractions_reviews_batch1_4.csv')\n",
    "attractions_review_batch1_5 = pd.read_csv('./raw_datasets/attactions_reviews_batch1/attractions_reviews_batch1_5.csv')\n",
    "attractions_review_batch1_6 = pd.read_csv('./raw_datasets/attactions_reviews_batch1/attractions_reviews_batch1_6.csv')\n",
    "attractions_review_batch1_7 = pd.read_csv('./raw_datasets/attactions_reviews_batch1/attractions_reviews_batch1_7.csv')\n",
    "attractions_review_batch2_1 = pd.read_csv('./raw_datasets/attactions_reviews_batch2/attractions_reviews_batch2_1.csv')\n",
    "attractions_review_batch2_2 = pd.read_csv('./raw_datasets/attactions_reviews_batch2/attractions_reviews_batch2_2.csv')\n",
    "attractions_review_batch2_3 = pd.read_csv('./raw_datasets/attactions_reviews_batch2/attractions_reviews_batch2_3.csv')\n",
    "attractions_review_batch2_4 = pd.read_csv('./raw_datasets/attactions_reviews_batch2/attractions_reviews_batch2_4.csv')\n",
    "attractions_review_batch2_5 = pd.read_csv('./raw_datasets/attactions_reviews_batch2/attractions_reviews_batch2_5.csv')\n",
    "attractions_review_batch2_6 = pd.read_csv('./raw_datasets/attactions_reviews_batch2/attractions_reviews_batch2_6.csv')\n",
    "\n",
    "att_review = pd.concat([attractions_review_batch1_1,attractions_review_batch1_2,attractions_review_batch1_3,attractions_review_batch1_4,\n",
    "                       attractions_review_batch1_5,attractions_review_batch1_6,attractions_review_batch1_7,attractions_review_batch2_1,\n",
    "                       attractions_review_batch2_2,attractions_review_batch2_3,attractions_review_batch2_4,attractions_review_batch2_5,\n",
    "                       attractions_review_batch2_6],ignore_index=True)\n",
    "\n",
    "att_review.to_csv('./datasets/attractions_review.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24a6cbf-0e27-497d-a17e-2d63f56c4b4d",
   "metadata": {},
   "source": [
    "## Now that data has been acquired, let's move on to do data cleaning and exploratory data analysis (EDA). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
